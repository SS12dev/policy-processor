# ============================================================================
# OpenAI Configuration
# ============================================================================
OPENAI_API_KEY=your_openai_api_key_here

# Model Selection
# Primary model: Used for simple tasks (document analysis, chunking)
OPENAI_MODEL_PRIMARY=gpt-4o-mini

# Secondary model: Used for complex tasks (policy extraction, decision trees)
OPENAI_MODEL_SECONDARY=gpt-4o

# API Limits and Timeouts
# Max tokens in model response (4096 is safe for gpt-4o-mini, 16384 for gpt-4o)
OPENAI_MAX_TOKENS=8192

# Temperature for generation (0.1 = very deterministic, good for policy extraction)
OPENAI_TEMPERATURE=0.1

# Max retries for failed API calls
OPENAI_MAX_RETRIES=3

# API timeout in seconds (300 = 5 minutes, increased for long policy documents)
OPENAI_TIMEOUT=300

# Concurrency Settings
# Max concurrent OpenAI API requests (2 = conservative, safe for rate limits)
# Set to 1 for fully sequential processing, 2-3 for moderate concurrency
OPENAI_MAX_CONCURRENT_REQUESTS=2

# Per-request timeout in seconds (300 = 5 minutes per individual request)
OPENAI_PER_REQUEST_TIMEOUT=300


# ============================================================================
# Redis Configuration (for state management and caching)
# ============================================================================
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=
REDIS_SOCKET_TIMEOUT=5
REDIS_SOCKET_CONNECT_TIMEOUT=5

# Default TTL for cached data in seconds (3600 = 1 hour)
REDIS_DEFAULT_TTL=3600


# ============================================================================
# Application Configuration
# ============================================================================
# A2A Server settings
APP_HOST=0.0.0.0
APP_PORT=8001

# Debug mode (set to true for development)
APP_DEBUG=false

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO


# ============================================================================
# Document Processing Configuration
# ============================================================================
# Chunking settings - CRITICAL for maintaining context
# Max tokens per chunk (8000 = large chunks for better context retention)
# Recommended: 6000-8000 for policy documents, 2000-4000 for shorter docs
MAX_CHUNK_TOKENS=8000

# Chunk overlap in tokens (600 = substantial overlap to prevent context loss)
# Recommended: 10-15% of MAX_CHUNK_TOKENS for good continuity
CHUNK_OVERLAP=600

# Confidence threshold for validation (0.0-1.0)
# 0.7 = fairly strict, 0.5 = more lenient
DEFAULT_CONFIDENCE_THRESHOLD=0.7

# Max concurrent processing jobs
MAX_CONCURRENT_JOBS=5

# Maximum document pages to process
MAX_DOCUMENT_PAGES=50


# ============================================================================
# Database Configuration
# ============================================================================
# SQLite database path (use sqlite:/// for local, postgresql:// for production)
DATABASE_URL=sqlite:///./data/policy_processor.db


# ============================================================================
# Performance Targets (for monitoring)
# ============================================================================
# Expected processing times (in seconds)
TARGET_PROCESSING_TIME_10_PAGES=45
TARGET_PROCESSING_TIME_30_PAGES=180
TARGET_PROCESSING_TIME_50_PAGES=300
